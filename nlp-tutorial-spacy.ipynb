{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import re","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"chat1='codebasics: Hello, I am having an issue with my order # 412889912'\n\npattern = 'order[^\\d]*(\\d*)'\nmatches = re.findall(pattern, chat1)\nmatches","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"chat2='codebasics: I have a problem with my order number 412889912'\npattern = 'order[^\\d]*(\\d*)'\nmatches = re.findall(pattern, chat2)\nmatches","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"chat3='codebasics: My order 412889912 is having an issue, I was charged 300$ when online it says 280$'\npattern = 'order[^\\d]*(\\d*)'\nmatches = re.findall(pattern, chat3)\nmatches","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_pattern_match(pattern, text):\n    matches = re.findall(pattern, text)\n    if matches:\n        return matches[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_pattern_match('order[^\\d]*(\\d*)', chat1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"chat1 = 'codebasics: you ask lot of questions üò†  1235678912, abc@xyz.com'\nchat2 = 'codebasics: here it is: (123)-567-8912, abc@xyz.com'\nchat3 = 'codebasics: yes, phone: 1235678912 email: abc@xyz.com'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_pattern_match('[a-zA-Z0-9_]*@[a-z]*\\.[a-zA-Z0-9]*',chat1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_pattern_match('(\\d{10})|(\\(\\d{3}\\)-\\d{3}-\\d{4})',chat2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text='''\nBorn Elon Reeve Musk\nJune 28, 1971 (age 50)\nPretoria, Transvaal, South Africa\nCitizenship \nSouth Africa (1971‚Äìpresent)\nCanada (1971‚Äìpresent)\nUnited States (2002‚Äìpresent)\nEducation University of Pennsylvania (BS, BA)\nTitle\nFounder, CEO and Chief Engineer of SpaceX\nCEO and product architect of Tesla, Inc.\nFounder of The Boring Company and X.com (now part of PayPal)\nCo-founder of Neuralink, OpenAI, and Zip2\nSpouse(s) \nJustine Wilson\n‚Äã\n‚Äã(m. 2000; div. 2008)‚Äã\nTalulah Riley\n‚Äã\n‚Äã(m. 2010; div. 2012)‚Äã\n‚Äã\n‚Äã(m. 2013; div. 2016)\n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_pattern_match(r'age (\\d+)', text)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_pattern_match(r'Born(.*)\\n', text).strip()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_pattern_match(r'\\(age.*\\n(.*)', text)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_pattern_match('Born.*\\n(.*)\\(age', text)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_personal_information(text):\n    age = get_pattern_match('age (\\d+)', text)\n    full_name = get_pattern_match('Born(.*)\\n', text)\n    birth_date = get_pattern_match('Born.*\\n(.*)\\(age', text)\n    birth_place = get_pattern_match('\\(age.*\\n(.*)', text)\n    return {\n        'age': int(age),\n        'name': full_name.strip(),\n        'birth_date': birth_date.strip(),\n        'birth_place': birth_place.strip()\n    }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text = '''\nBorn\tMukesh Dhirubhai Ambani\n19 April 1957 (age 64)\nAden, Colony of Aden\n(present-day Yemen)[1][2]\nNationality\tIndian\nAlma mater\t\nSt. Xavier's College, Mumbai\nInstitute of Chemical Technology (B.E.)\nStanford University (drop-out)\nOccupation\tChairman and MD, Reliance Industries\nSpouse(s)\tNita Ambani ‚Äã(m. 1985)‚Äã[3]\nChildren\t3\nParent(s)\t\nDhirubhai Ambani (father)\nKokilaben Ambani (mother)\nRelatives\tAnil Ambani (brother)\nTina Ambani (sister-in-law)\n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"extract_personal_information(text)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SPACY vs NLTK","metadata":{}},{"cell_type":"code","source":"import spacy","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nlp = spacy.load(\"en_core_web_sm\")\n\ndoc = nlp(\"Dr. Strange loves pav bhaji of mumbai. Hulk loves chaat of delhi\")\n\nfor sentence in doc.sents:\n    print(sentence)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for sentence in doc.sents:\n    for word in sentence:\n        print(word)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk.tokenize import sent_tokenize\n\nsent_tokenize(\"Dr. Strange loves pav bhaji of mumbai. Hulk loves chaat of delhi\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk.tokenize import word_tokenize\n\nword_tokenize(\"Dr. Strange loves pav bhaji of mumbai. Hulk loves chaat of delhi\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Spacy ","metadata":{}},{"cell_type":"code","source":"import spacy","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a blank pipeline of a given language class\nnlp = spacy.blank(\"en\")\ndoc = nlp(\"Dr. Strange loves pav bhaji of mumbai as it costs only 2$ per plate.\")\n\nfor token in doc:\n    print(token)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"span = doc[1:5]\ntype(span)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"doc = nlp(\"Tony gave two $ to Peter.\")\ntoken0 = doc[0]\ntoken0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"token3 = doc[3]\ntoken3.text","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"token3.is_currency","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for token in doc:\n    print(token, \"==>\", \"index: \", token.i,\n         \"is_alpha:\", token.is_alpha,\n         \"is_punct:\", token.is_punct,\n         \"like_num:\", token.like_num,\n         \"is_currency:\", token.is_currency,\n         )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# with open(\"students.txt\") as f:\n#     text = f.readlines()\n# text","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# text = \" \".join(text)\n# text","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# doc = nlp(text)\n# emails = []\n# for token in doc:\n#     if token.like_email:\n#         emails.append(token.text)\n# emails   ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Support in other languages","metadata":{}},{"cell_type":"code","source":"nlp = spacy.blank(\"hi\")\ndoc = nlp(\"‡§≠‡•à‡§Ø‡§æ ‡§ú‡•Ä! 5000 ‚Çπ ‡§â‡§ß‡§æ‡§∞ ‡§•‡•á ‡§µ‡•ã ‡§µ‡§æ‡§™‡§∏ ‡§¶‡•á‡§¶‡•ã\")\nfor token in doc:\n    print(token, token.is_currency)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Customizing tokenizer","metadata":{}},{"cell_type":"code","source":"from spacy.symbols import ORTH\n\nnlp = spacy.blank(\"en\")\ndoc = nlp(\"gimme double cheese extra large healthy pizza\")\ntokens = [token.text for token in doc]\ntokens","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nlp.tokenizer.add_special_case(\"gimme\", [\n    {ORTH: \"gim\"},\n    {ORTH: \"me\"},\n])\ndoc = nlp(\"gimme double cheese extra large healthy pizza\")\ntokens = [token.text for token in doc]\ntokens","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Sentence Tokenization or Segmentation","metadata":{}},{"cell_type":"code","source":"# doc = nlp(\"Dr. Strange loves pav bhaji of mumbai. Hulk loves chat of delhi\")\n# for sentence in doc.sents:\n#     print(sentence)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# nlp = spacy.blank('en')\nnlp.pipeline\nnlp.add_pipe('sentencizer')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"doc = nlp(\"Dr. Strange loves pav bhaji of mumbai. Hulk loves chat of delhi\")\nfor sentence in doc.sents:\n    print(sentence)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nlp.pipeline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text='''\nLook for data to help you address the question. Governments are good\nsources because data from public research is often freely available. Good\nplaces to start include http://www.data.gov/, and http://www.science.\ngov/, and in the United Kingdom, http://data.gov.uk/.\nTwo of my favorite data sets are the General Social Survey at http://www3.norc.org/gss+website/, \nand the European Social Survey at http://www.europeansocialsurvey.org/.\n'''\n\ndoc = nlp(text)\nurls = []\nfor token in doc:\n    if token.like_url:\n        urls.append(token.text.strip(\".\"))\nurls","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transactions = \"Tony gave two $ to Peter, Bruce gave 500 ‚Ç¨ to Steve\"\n\ndoc = nlp(transactions)\nfor token in doc:\n    if token.like_num and doc[token.i+1].is_currency:\n        print(token.text, doc[token.i+1].text)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pipelines","metadata":{}},{"cell_type":"code","source":"import spacy\n\nnlp = spacy.blank(\"en\")\n\ndoc = nlp(\"Captain america ate 100$ of samosa. Then he said I can do this all day.\")\n\nfor token in doc:\n    print(token)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nlp.pipe_names","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nlp = spacy.load(\"en_core_web_sm\")\nnlp.pipe_names","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nlp.pipeline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"doc = nlp(\"Captain america ate 100$ of samosa. Then he said I can do this all day.\")\n\nfor token in doc:\n    print(token, \" | \", spacy.explain(token.pos_), \" | \", token.lemma_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Named Entity Recognition","metadata":{}},{"cell_type":"code","source":"doc = nlp(\"Tesla Inc is going to acquire twitter for $45 billion\")\nfor ent in doc.ents:\n    print(ent.text, ent.label_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from spacy import displacy\n\ndisplacy.render(doc, style=\"ent\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# python -m spacy download fr_core_news_sm\n# nlp = spacy.load(\"fr_core_news_sm\")\n# doc = nlp(\"Tesla Inc va racheter Twitter pour $45 milliards de dollars\")\n# for ent in doc.ents:\n#     print(ent.text, \" | \", ent.label_, \" | \", spacy.explain(ent.label_))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Adding a component to a blank pipeline","metadata":{}},{"cell_type":"code","source":"source_nlp = spacy.load(\"en_core_web_sm\")\n\nnlp = spacy.blank(\"en\")\nnlp.add_pipe(\"ner\", source=source_nlp)\nnlp.pipe_names","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"doc = nlp(\"Tesla Inc is going to acquire twitter for $45 billion\")\nfor ent in doc.ents:\n    print(ent.text, ent.label_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Stemming in NLTK\n","metadata":{}},{"cell_type":"code","source":"from nltk.stem import PorterStemmer\nstemmer = PorterStemmer()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"words = [\"eating\", \"eats\", \"eat\", \"ate\", \"adjustable\", \"rafting\", \"ability\", \"meeting\"]\n\nfor word in words:\n    print(word, \"|\", stemmer.stem(word))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lemmatization in Spacy","metadata":{}},{"cell_type":"code","source":"nlp = spacy.load(\"en_core_web_sm\")\n\ndoc = nlp(\"Mando talked for 3 hours although talking isn't his thing\")\ndoc = nlp(\"eating eats eat ate adjustable rafting ability meeting better\")\nfor token in doc:\n    print(token, \" | \", token.lemma_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Customizing lemmatizer\n","metadata":{}},{"cell_type":"code","source":"nlp.pipe_names","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ar = nlp.get_pipe('attribute_ruler')\n\nar.add([[{\"TEXT\":\"Bro\"}],[{\"TEXT\":\"Brah\"}]],{\"LEMMA\":\"Brother\"})\n\ndoc = nlp(\"Bro, you wanna go? Brah, don't say no! I am exhausted\")\nfor token in doc:\n    print(token.text, \"|\", token.lemma_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"doc[6].lemma_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# POS tags","metadata":{}},{"cell_type":"code","source":"nlp = spacy.load(\"en_core_web_sm\")\ndoc = nlp(\"Elon flew to mars yesterday. He carried biryani masala with him\")\n\nfor token in doc:\n    print(token,\" | \", token.pos_, \" | \", spacy.explain(token.pos_))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"doc = nlp(\"Wow! Dr. Strange made 265 million $ on the very first day\")\n\nfor token in doc:\n    print(token,\" | \", token.pos_, \" | \", spacy.explain(token.pos_))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"doc = nlp(\"He quits the job\")\n\nprint(doc[1].text, \"|\", doc[1].tag_, \"|\", spacy.explain(doc[1].tag_))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"doc = nlp(\"he quit the job\")\n\nprint(doc[1].text, \"|\", doc[1].tag_, \"|\", spacy.explain(doc[1].tag_))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Removing all SPACE, PUNCT and X token from text","metadata":{}},{"cell_type":"code","source":"earnings_text=\"\"\"Microsoft Corp. today announced the following results for the quarter ended December 31, 2021, as compared to the corresponding period of last fiscal year:\n\n¬∑         Revenue was $51.7 billion and increased 20%\n¬∑         Operating income was $22.2 billion and increased 24%\n¬∑         Net income was $18.8 billion and increased 21%\n¬∑         Diluted earnings per share was $2.48 and increased 22%\n‚ÄúDigital technology is the most malleable resource at the world‚Äôs disposal to overcome constraints and reimagine everyday work and life,‚Äù said Satya Nadella, chairman and chief executive officer of Microsoft. ‚ÄúAs tech as a percentage of global GDP continues to increase, we are innovating and investing across diverse and growing markets, with a common underlying technology stack and an operating model that reinforces a common strategy, culture, and sense of purpose.‚Äù\n‚ÄúSolid commercial execution, represented by strong bookings growth driven by long-term Azure commitments, increased Microsoft Cloud revenue to $22.1 billion, up 32% year over year‚Äù said Amy Hood, executive vice president and chief financial officer of Microsoft.\"\"\"\n\ndoc = nlp(earnings_text)\n\nfiltered_tokens = []\n\nfor token in doc:\n    if token.pos_ not in [\"SPACE\", \"PUNCT\", \"X\"]:\n        filtered_tokens.append(token)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count = doc.count_by(spacy.attrs.POS)# 96 propn number meaning 13 proper nouns in text\ncount","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"doc.vocab[96].text","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for k,v in count.items():\n    print(doc.vocab[k].text, \"|\",v) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"doc = nlp(\"Michael Bloomberg founded Bloomberg in 1982\")\nfor ent in doc.ents:\n    print(ent.text, \"|\", ent.label_, \"|\", spacy.explain(ent.label_))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"doc = nlp(\"Tesla is going to acquire Twitter for $45 billion\")\nfor ent in doc.ents:\n    print(ent.text, \" | \", ent.label_, \" | \", ent.start_char, \"|\", ent.end_char)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from spacy.tokens import Span\n\ns1 = Span(doc, 0, 1, label=\"ORG\")\ns2 = Span(doc, 5, 6, label=\"ORG\")#starts 5 to 6 not included\n\ndoc.set_ents([s1, s2], default=\"unmodified\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for ent in doc.ents:\n    print(ent.text, \" | \", ent.label_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nlp = spacy.load(\"en_core_web_sm\")\n\ntext = \"\"\"Kiran want to know the famous foods in each state of India. So, he opened Google and search for this question. Google showed that\nin Delhi it is Chaat, in Gujarat it is Dal Dhokli, in Tamilnadu it is Pongal, in Andhrapradesh it is Biryani, in Assam it is Papaya Khar,\nin Bihar it is Litti Chowkha and so on for all other states\"\"\"\n# extract all geographical names\ndoc = nlp(text)\n\nfor ent in doc.ents:\n    print(ent.text, \" | \", ent.label_, \" | \", spacy.explain(ent.label_))\n\ngeo_names = []\n\nfor ent in doc.ents:\n    if ent.label_ in [\"GPE\"]:\n        geo_names.append(ent.text)\n        \nprint(\"GeoLocation Names: \", geo_names, \"\\n\", \"Count: \", len(geo_names))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text = \"\"\"Sachin Tendulkar was born on 24 April 1973, Virat Kholi was born on 5 November 1988, Dhoni was born on 7 July 1981\nand finally Ricky ponting was born on 19 December 1974.\"\"\"\n\ndoc = nlp(text)\n\n#list for storing all the dates\nall_birth_dates = []\n\nfor ent in doc.ents:\n    if ent.label_ in [\"DATE\"]:\n        all_birth_dates.append(ent.text)\n\n#finally printing the results\nprint(\"All Birth Dates: \", all_birth_dates)\nprint(\"Count: \", len(all_birth_dates))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}